Prompting an LLM in code

Code cell 1: Set up programming environment to use code to send prompts to OpenAI's cloud-hosted service.

import openai
import os
​
openai.api_key = os.getenv("OPENAI_API_KEY")
​
def llm_response(prompt):
    response = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[{'role':'user','content':prompt}],
        temperature=0
    )
    return response.choices[0].message['content']
Code cell 2: Define a prompt that will classify the sentiment of a restaurant review.

prompt = '''
    Classify the following review 
    as having either a positive or
    negative sentiment:
​
    The banana pudding was really tasty!
'''
​
response = llm_response(prompt)
print(response)
